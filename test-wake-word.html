<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wake Word Detection Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
        }
        .listening {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
        }
        .stopped {
            background-color: #f8d7da;
            border: 1px solid #f5c6cb;
        }
        #transcript {
            min-height: 100px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            margin: 10px 0;
            background-color: #f9f9f9;
        }
        #log {
            max-height: 300px;
            overflow-y: auto;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            background-color: #f0f0f0;
            font-family: monospace;
            font-size: 12px;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            font-size: 16px;
            cursor: pointer;
        }
        .detected {
            color: green;
            font-weight: bold;
        }
        .partial {
            color: orange;
        }
    </style>
</head>
<body>
    <h1>Wake Word Detection Test</h1>
    <p>Say "Hey EndoFlow" to test wake word detection</p>
    
    <div id="status" class="status stopped">Not Listening</div>
    
    <button id="startBtn">Start Listening</button>
    <button id="stopBtn" disabled>Stop Listening</button>
    <button id="clearBtn">Clear Log</button>
    
    <h3>Current Transcript:</h3>
    <div id="transcript"></div>
    
    <h3>Accumulated Transcript:</h3>
    <div id="accumulated"></div>
    
    <h3>Detection Log:</h3>
    <div id="log"></div>
    
    <script>
        let recognition = null;
        let isListening = false;
        let accumulatedTranscript = '';
        let transcriptHistory = [];
        
        const statusEl = document.getElementById('status');
        const transcriptEl = document.getElementById('transcript');
        const accumulatedEl = document.getElementById('accumulated');
        const logEl = document.getElementById('log');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        
        function log(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const className = type === 'detected' ? 'detected' : type === 'partial' ? 'partial' : '';
            logEl.innerHTML += `<div class="${className}">[${timestamp}] ${message}</div>`;
            logEl.scrollTop = logEl.scrollHeight;
        }
        
        function checkWakeWord(transcript) {
            const normalized = transcript.toLowerCase().replace(/\s+/g, ' ').trim();
            log(`Checking: "${normalized}"`);
            
            // Direct patterns
            const directPatterns = [
                'hey endoflow',
                'hey endo flow',
                'hey end flow',
                'hi endoflow',
                'hi endo flow',
                'endoflow',
                'endo flow'
            ];
            
            for (const pattern of directPatterns) {
                if (normalized.includes(pattern)) {
                    log(`âœ… WAKE WORD DETECTED! Pattern: "${pattern}"`, 'detected');
                    return true;
                }
            }
            
            // Partial matches
            const hasHey = normalized.includes('hey') || normalized.includes('hi');
            const hasEndo = normalized.includes('endo') || normalized.includes('end o') || normalized.includes('and o');
            const hasFlow = normalized.includes('flow') || normalized.includes('flo');
            const hasEnd = normalized.includes('end') || normalized.includes('and');
            
            if (hasHey) log(`Found "hey/hi"`, 'partial');
            if (hasEndo) log(`Found "endo" variation`, 'partial');
            if (hasFlow) log(`Found "flow" variation`, 'partial');
            if (hasEnd) log(`Found "end" variation`, 'partial');
            
            if ((hasHey && hasEndo) || (hasHey && hasFlow) || (hasEndo && hasFlow)) {
                log(`âœ… WAKE WORD DETECTED! Strong partial match`, 'detected');
                return true;
            }
            
            if (hasHey && hasEnd && normalized.length > 5) {
                log(`âœ… WAKE WORD DETECTED! Hey+End pattern`, 'detected');
                return true;
            }
            
            return false;
        }
        
        function startListening() {
            if (isListening) return;
            
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';
                recognition.maxAlternatives = 3;
                
                recognition.onstart = () => {
                    isListening = true;
                    statusEl.textContent = 'Listening...';
                    statusEl.className = 'status listening';
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    log('Started listening');
                };
                
                recognition.onresult = (event) => {
                    let currentTranscript = '';
                    
                    // Process all results
                    for (let i = 0; i < event.results.length; i++) {
                        const result = event.results[i];
                        const transcript = result[0].transcript;
                        currentTranscript += transcript + ' ';
                        
                        // Log alternatives
                        if (result.length > 1) {
                            for (let j = 1; j < Math.min(result.length, 3); j++) {
                                log(`Alternative ${j}: "${result[j].transcript}"`);
                            }
                        }
                    }
                    
                    currentTranscript = currentTranscript.trim();
                    transcriptEl.textContent = currentTranscript;
                    
                    // Update accumulated
                    accumulatedTranscript = currentTranscript;
                    accumulatedEl.textContent = accumulatedTranscript;
                    
                    log(`Result: "${currentTranscript}"`);
                    
                    // Check for wake word
                    if (checkWakeWord(accumulatedTranscript)) {
                        // Play a sound or visual feedback
                        statusEl.textContent = 'ðŸŽ‰ WAKE WORD DETECTED!';
                        statusEl.style.backgroundColor = '#28a745';
                        statusEl.style.color = 'white';
                        
                        setTimeout(() => {
                            statusEl.textContent = 'Listening...';
                            statusEl.style.backgroundColor = '';
                            statusEl.style.color = '';
                            statusEl.className = 'status listening';
                            accumulatedTranscript = '';
                            accumulatedEl.textContent = '';
                        }, 2000);
                    }
                };
                
                recognition.onerror = (event) => {
                    log(`Error: ${event.error}`);
                    if (event.error === 'no-speech') {
                        log('No speech detected, continuing...');
                    }
                };
                
                recognition.onend = () => {
                    log('Recognition ended');
                    if (isListening) {
                        log('Restarting...');
                        setTimeout(() => {
                            if (isListening) {
                                try {
                                    recognition.start();
                                } catch (e) {
                                    log(`Restart error: ${e.message}`);
                                }
                            }
                        }, 100);
                    } else {
                        statusEl.textContent = 'Stopped';
                        statusEl.className = 'status stopped';
                        startBtn.disabled = false;
                        stopBtn.disabled = true;
                    }
                };
                
                recognition.start();
            } else {
                alert('Speech recognition not supported in this browser');
            }
        }
        
        function stopListening() {
            isListening = false;
            if (recognition) {
                recognition.stop();
            }
        }
        
        startBtn.addEventListener('click', startListening);
        stopBtn.addEventListener('click', stopListening);
        clearBtn.addEventListener('click', () => {
            logEl.innerHTML = '';
            transcriptEl.textContent = '';
            accumulatedEl.textContent = '';
            accumulatedTranscript = '';
        });
        
        // Request microphone permission on page load
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(() => log('Microphone permission granted'))
            .catch(err => log(`Microphone permission error: ${err.message}`));
    </script>
</body>
</html>